# awseasy.s3c

#.
#. AWS S3 commands
#.

#
[[ "$OSTYPE" == "linux-gnu" ]] && databin='/bin/date'
[[ "$OSTYPE" == "darwin"* ]] && databin='/usr/local/bin/gdate'

#.  s3ls - AWS S3 -- AWS/S3 list files
s3ls() {

myACCOUNT=$(aws iam list-account-aliases | tr -d '{|}|[|]|"| ' | egrep -v ':|^$');
echo; singlewide Account $myACCOUNT ; echo ${RESET}

  aws s3 ls s3://${1}
  echo
  sameAs "aws s3 ls s3://${1}"
  echo
}

#.  s3stat - AWS S3 -- AWS/S3 long listing
s3stat() {

myACCOUNT=$(aws iam list-account-aliases | tr -d '{|}|[|]|"| ' | egrep -v ':|^$');
echo; singlewide Account $myACCOUNT ; echo ${RESET}

Buckets=

[ $# -ge 1 ] && {
  Buckets=${1}
} || {
  Buckets=$(aws s3 ls | awk '{print $3}')
}
#
BucketCnt=$(echo "$Buckets" | grep '^20' | wc -l | tr -d ' ')

[ $BucketCnt -eq 1 ] && { Buckets=${1} ; }
for b in $Buckets; do

    echo "   s3://${b}"                       # this up here, in case it gets hung

    S3bsize=0;S3bfiles=0;S3dused=0;S3since=0000-00-00;S3last=0000-00-00;S3quiet=0

    S3raw=$(aws s3 ls s3://${b} --summarize --human-readable --recursive )

    S3region=$(aws s3api get-bucket-location --bucket ${b})
    _S3Location=$(_ec2parse "$S3region" LocationConstraint);

    S3bsize=$(echo "${S3raw}" | grep 'Total.Size' | cut -d':' -f2 | tr -s ' ')
    S3bfiles=$(echo "${S3raw}" | grep 'Total.Objects' | cut -d':' -f2 | tr -d ' ')

    # stats calc
    S3raw2=$(echo "${S3raw}" | grep '^20' | awk '{print $1}' | sort | uniq -c )
    S3dused=$(echo "${S3raw2}" | wc -l | tr -d ' ' )
    S3since=$(echo "${S3raw2}" | head -1 | awk '{print $2}')

    # no activity calc
    S3last=$(echo "${S3raw2}" | tail -1 | awk '{print $2}')
    S3quiet=$(echo "$(( ($( $databin +%s ) - $( $databin --date="${S3last}" +%s ) )/(60*60*24) )) days")

    #
    # descDUMP 'Owner' "${_S3owner}" 'Perms' "${_S3perms}"
    doubleDUMP 'Bucket Size' "${S3bsize}" 'Files' "${S3bfiles}"
    doubleDUMP 'Since' "${S3since}" 'Last' "${S3last}"
    doubleDUMP 'Days Used' "${S3dused}" 'Dormant' "${S3quiet}"
    singleDUMP 'Location' "${_S3Location}"
    echo "${RESET}"
done
}

#.  s3deep - AWS S3 -- AWS/S3 list recursively
s3deep() {

if (( $# < 1 )); then
 echo usage: Needs at least one argument {instance ID#}
 return
fi

  myACCOUNT=$(aws iam list-account-aliases | tr -d '{|}|[|]|"| ' | egrep -v ':|^$');
  echo; doublewide Account $myACCOUNT Bucket $1; echo ${RESET}

  aws s3 ls --summarize --human-readable --recursive s3://${1}
  echo
  sameAs "aws s3 ls --summarize --human-readable --recursive s3://${1}"
  echo
}

#.  s3push - AWS S3 -- AWS/S3 push local data to s3
s3push() {

  echo 's3cp is not fully functional yet'
  echo please use : 'aws s3 cp local-sourcefile s3://target-s3bucket/'
}

#.  s3pull - AWS S3 -- AWS/S3 pull get info from s3
s3pull() {

  echo 's3cp is not fully functional yet'
  echo please use : 'aws s3 cp s3://target-s3bucket/' local-destination
}

#.  s3make - AWS S3 -- AWS/S3 make/create new s3 bucket
s3make() {

if (( $# < 1 )); then
 echo usage: Needs at least one argument {instance ID#}
 return
fi

  echo "${CYAN} executing command: ${GRAY} aws s3api create-bucket --bucket s3bucketName --region us-east-1 ${RESET}"
  aws s3api create-bucket --bucket $1 --region us-east-1
}

#.  s3rm - AWS S3 -- AWS/S3 remove files (recursive)
s3rm() {
if (( $# < 1 )); then
 echo usage: Needs at least one argument {Bucket Name}
 return
fi

  aws s3 rm --recursive s3://${1}
  echo
  sameAs "aws s3 rm --recursive s3://${1}"
  echo
}

#.  s3rb - AWS S3 -- AWS/S3 Remove Bucket (with Force)
s3rb () {
if (( $# < 1 )); then
 echo usage: Needs at least one argument {Bucket Name}
 return
fi

  aws s3 rb --force s3://${1}
  echo
  sameAs "aws s3 rb --force s3://${1}"
  echo
}

# #.  s3rmold - AWS S3 -- AWS/S3 remove old files (recursive) any older than 30 days
# s3rmold() {
# if (( $# < 1 )); then
#  echo usage: Needs at least one argument {30 days}
#  return
# fi
#
# s3cmd ls s3://${1} | while read -r line;
#   do
#     echo $line
#     createDate=$(echo $line|awk {'print $1" "$2'})
#     createDate=$( $databin -d"$createDate" +%s)
#     olderThan=$( $databin -d"-$2" +%s)
#     if [[ $createDate -lt $olderThan ]]
#       then
#         fileName=$(echo $line|awk {'print $4'})
#         echo $fileName
#         if [[ $fileName != "" ]]
#           then
#             s3cmd del "$fileName"
#         fi
#     fi
#   done;
# }
#
# #####
#
# # admin-portal-elb-logs
#
#    s3://admin-portal-elb-logs
#     Bucket Size: [  3.5 MiB ] Files: [ 13607 ]
#     Since: [ 2015-12-01 ] Last: [ 2016-06-01 ]
#     Days Used: [ 184 ] Dormant: [ 366 days ]
#     Location: [ null ]
#
# jld0517@UKRA:~$ s3cmd ls s3://admin-portal-elb-logs
#                       DIR   s3://admin-portal-elb-logs/AWSLogs/
#
# ######
#
#
#  #
#
#     s3://proccessminerconsolelog
#     Bucket Size: [ 303.9MiB ] Files: [ 424188 ]
#     Since: [ 2016-12-19 ] Last: [ 2017-06-02 ]
#     Days Used: [ 166 ] Dormant: [ 0 days ]
#

#.  s3help - AWS S3 -- AWS/S3 pull get info from s3
s3help() {

  echo s3ls      -- AWS/S3 list files Quick
  echo s3long    -- AWS/S3 list files Slow with details
  echo s3deep    -- AWS/S3 list recursively
  echo s3push    -- AWS/S3 push local data to s3
  echo s3pull    -- AWS/S3 pull get info from s3
  echo s3make    -- AWS/S3 make/create new s3 bucket
  echo s3rm      -- AWS/S3 empties all files
  echo s3rmold   -- AWS/S3 empties all files with a given age -- coming soon
  echo s3rb      -- AWS/S3 removes bucket with force
}
#
